---
title: "Text mining HTM"
output: html_document
date: "2025-05-28"
---


```{r setup}
# Set the CRAN mirror:
local({r <- getOption("repos")
r["CRAN"] <- "https://cran.rstudio.com/"
options(repos = r)})

# Install the packages used in this tutorial:
packages <- c("cld2", "quanteda", "seededlda", "sentimentr")

for (i in packages) {
    if(!require(i, character.only = TRUE)) {
        install.packages(i, dependencies = TRUE)
    }
}
```

```{r data}
#copenhagen_reviews <- read.csv("copenhagen_reviews.csv")
copenhagen_reviews <- copenhagen_reviews[ sample(nrow(copenhagen_reviews), 10000), ]
```


```{r explore copenhagen review data}
str(copenhagen_reviews)
length(unique(copenhagen_reviews$id))
copenhagen_reviews <- copenhagen_reviews[ !is.na(copenhagen_reviews$comments), ] #missing values
```

```{r assign language}
copenhagen_reviews$language <- cld2::detect_language(copenhagen_reviews$comments)
head(cbind(table(copenhagen_reviews$language)), 20)
copenhagen_reviews <- copenhagen_reviews[ which(copenhagen_reviews$language %in% "en"), ] #Filter language

```

```{r non_ascii}
copenhagen_reviews$non_ascii <- grepl("[^\x01-\x7F]", copenhagen_reviews$comments)
copenhagen_reviews[ which(copenhagen_reviews$non_ascii %in% TRUE)[30], ]$comments
copenhagen_reviews$comments <- gsub("[^\x01-\x7F]", "", copenhagen_reviews$comments) #Remove non ascii

```

```{r creation of corpus}
corpus <- quanteda::corpus(copenhagen_reviews, 
                           docid_field = "id",
                           text_field = "comments")

summary(corpus, 10)

```

```{r corpus random draw}
as.character(corpus[ sample(length(corpus), 1) ])
```

```{r sentimentr}
quanteda::docvars(corpus, field = "ave_sentiment") <- sentimentr::sentiment_by(sentimentr::get_sentences(corpus))$ave_sentiment
```

```{r plot sentiment scores}
hist(quanteda::docvars(corpus)$ave_sentiment)
```

```{r explore sentiments}
as.character(corpus[ which(quanteda::docvars(corpus)$ave_sentiment == summary(quanteda::docvars(corpus)$ave_sentiment)[1]), ])
as.character(corpus[ which(quanteda::docvars(corpus)$ave_sentiment == summary(quanteda::docvars(corpus)$ave_sentiment)[6]), ])
```

```{r feature tokenization}
tokens <- quanteda::tokens(corpus, 
                           what = "word", # change the keyword
                           remove_punct = TRUE,
                           remove_symbols = TRUE,
                           remove_numbers = TRUE,
                           remove_url = TRUE,
                           remove_separators = TRUE,
                           split_hyphens = FALSE,
                           split_tags = FALSE,
                           include_docvars = TRUE,
                           padding = FALSE,
                           verbose = TRUE)
```

```{r tokens sample}
tokens[ sample(length(tokens), 1) ]
```

```{r keywords in context}
data.frame(quanteda::kwic(tokens, pattern = "loud"))[ c(1:5), c(4:6) ] #Change the word loud
tokens <- quanteda::tokens_tolower(tokens)
```

```{r explore stopwords}
quanteda::stopwords("en")
tokens <- quanteda::tokens_remove(tokens, pattern = stopwords("en"))
```

```{r dfm creation}
dfm <- quanteda::dfm(tokens)
dfm
topfeatures(dfm)
```


